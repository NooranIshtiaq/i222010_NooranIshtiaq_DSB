{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f7e093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23096133",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"Dataset/images\"\n",
    "annotations_folder = \"Dataset/annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44046ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class DatasetLoader:\n",
    "    def __init__(self, img_folder, ann_folder, num_classes=8, augment=False):\n",
    "        self.img_folder = img_folder\n",
    "        self.ann_folder = ann_folder\n",
    "        self.num_classes = num_classes\n",
    "        self.valid_exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "        self.augment = augment\n",
    "\n",
    "    def _read_annotation(self, idx):\n",
    "        exp = np.load(os.path.join(self.ann_folder, f\"{idx}_exp.npy\"))\n",
    "        val = np.load(os.path.join(self.ann_folder, f\"{idx}_val.npy\"))\n",
    "        aro = np.load(os.path.join(self.ann_folder, f\"{idx}_aro.npy\"))\n",
    "        try:\n",
    "            lnd = np.load(os.path.join(self.ann_folder, f\"{idx}_lnd.npy\"))\n",
    "        except FileNotFoundError:\n",
    "            lnd = None\n",
    "        return int(exp), float(val), float(aro), lnd\n",
    "\n",
    "    def _manual_augment(self, image):\n",
    "        \"\"\"Apply random augmentation using OpenCV + NumPy\"\"\"\n",
    "        choice = random.choice([\"flip\", \"rotate\", \"bright\", \"noise\"])\n",
    "        \n",
    "        if choice == \"flip\":\n",
    "            image = cv2.flip(image, 1)  # horizontal flip\n",
    "        elif choice == \"rotate\":\n",
    "            (h, w) = image.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((w // 2, h // 2), angle=random.randint(-15, 15), scale=1.0)\n",
    "            image = cv2.warpAffine(image, M, (w, h))\n",
    "        elif choice == \"bright\":\n",
    "            alpha = random.uniform(0.8, 1.2)   # contrast\n",
    "            beta = random.randint(-30, 30)    # brightness\n",
    "            image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "        elif choice == \"noise\":\n",
    "            noise = np.random.normal(0, 20, image.shape).astype(np.uint8)\n",
    "            image = cv2.add(image, noise)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def dataframe(self):\n",
    "        image_files = [\n",
    "            f for f in os.listdir(self.img_folder)\n",
    "            if os.path.splitext(f)[1].lower() in self.valid_exts\n",
    "        ]\n",
    "\n",
    "        indices = [os.path.splitext(f)[0] for f in image_files]\n",
    "\n",
    "        rows = []\n",
    "        for idx, fname in zip(indices, image_files):\n",
    "            try:\n",
    "                exp, val, aro, lnd = self._read_annotation(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {idx}, annotation missing or error: {e}\")\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(self.img_folder, fname)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            # apply augmentation if enabled\n",
    "            if self.augment:\n",
    "                image = self._manual_augment(image)\n",
    "\n",
    "            rows.append({\n",
    "                \"idx\": idx,\n",
    "                \"filename\": img_path,\n",
    "                \"image\": image,   # augmented or original image\n",
    "                \"expression\": exp,\n",
    "                \"valence\": val,\n",
    "                \"arousal\": aro,\n",
    "                \"landmarks\": lnd\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows).sort_values(\"filename\").reset_index(drop=True)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711a321",
   "metadata": {},
   "source": [
    "# Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "862c0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f34df8",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a47e9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = (224,224)\n",
    "def preprocess(df, num_classes=8):\n",
    "    X, y_class, y_reg = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        img = cv2.resize(row['image'], IMG_SIZE)\n",
    "        img = img.astype(\"float32\") / 255.0\n",
    "        X.append(img)\n",
    "        y_class.append(row['expression'])\n",
    "        y_reg.append([row['valence'], row['arousal']])\n",
    "    X = np.array(X)\n",
    "    y_class = to_categorical(y_class, num_classes=num_classes)\n",
    "    y_reg = np.array(y_reg, dtype=\"float32\")\n",
    "    return X, {\"expression\": y_class, \"va\": y_reg}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f242231",
   "metadata": {},
   "source": [
    "# Model Builder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f869c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, applications\n",
    "\n",
    "def build_model(input_shape=(224,224,3), num_classes=8, backbone=\"ResNet50\"):\n",
    "\n",
    "    if backbone == \"ResNet50\":\n",
    "        base = keras.applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    elif backbone == \"EfficientNetB0\":\n",
    "        base = keras.applications.EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    elif backbone == \"MobileNetV2\":\n",
    "        base = keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    elif backbone == \"DenseNet121\":\n",
    "        base = keras.applications.DenseNet121(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    elif backbone == \"Xception\":\n",
    "        base = keras.applications.Xception(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Backbone {backbone} not supported\")\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # classification head\n",
    "    cls = layers.Dense(256, activation=\"relu\")(x)\n",
    "    cls = layers.Dropout(0.3)(cls)\n",
    "    cls_out = layers.Dense(num_classes, activation=\"softmax\", name=\"expression\")(cls)\n",
    "\n",
    "    # regression head\n",
    "    reg = layers.Dense(128, activation=\"relu\")(x)\n",
    "    reg_out = layers.Dense(2, activation=\"tanh\", name=\"va\")(reg)\n",
    "\n",
    "    model = models.Model(inputs=base.input, outputs=[cls_out, reg_out], name=f\"multitask_{backbone}\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03caa5c",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01605b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DatasetLoader(images_folder, annotations_folder)\n",
    "df = loader.dataframe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe00300",
   "metadata": {},
   "source": [
    "# Splitting Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d13ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df['expression'], random_state=42\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08f05651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess(train_df)\n",
    "X_val, y_val     = preprocess(val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e745f3",
   "metadata": {},
   "source": [
    "# Training Using ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89178872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = build_model(backbone=\"ResNet50\", num_classes=df['expression'].nunique())\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"expression\": \"categorical_crossentropy\", \"va\": \"mse\"},\n",
    "    loss_weights={\"expression\": 1.0, \"va\": 1.0},\n",
    "    metrics={\"expression\": \"accuracy\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "690d35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1364s\u001b[0m 13s/step - expression_accuracy: 0.2038 - expression_loss: 2.1022 - loss: 2.4299 - va_loss: 0.3276 - val_expression_accuracy: 0.1250 - val_expression_loss: 2.0804 - val_loss: 2.2616 - val_va_loss: 0.1812\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1241s\u001b[0m 12s/step - expression_accuracy: 0.2504 - expression_loss: 1.8890 - loss: 2.0834 - va_loss: 0.1943 - val_expression_accuracy: 0.1225 - val_expression_loss: 2.0899 - val_loss: 2.2780 - val_va_loss: 0.1882\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1260s\u001b[0m 13s/step - expression_accuracy: 0.2554 - expression_loss: 1.9039 - loss: 2.0965 - va_loss: 0.1925 - val_expression_accuracy: 0.1250 - val_expression_loss: 5.1486 - val_loss: 5.8639 - val_va_loss: 0.7153\n",
      "Epoch 4/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1337s\u001b[0m 13s/step - expression_accuracy: 0.2967 - expression_loss: 1.7879 - loss: 1.9576 - va_loss: 0.1697 - val_expression_accuracy: 0.1250 - val_expression_loss: 133.9720 - val_loss: 134.6876 - val_va_loss: 0.7156\n",
      "Epoch 5/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1306s\u001b[0m 13s/step - expression_accuracy: 0.3360 - expression_loss: 1.7078 - loss: 1.8611 - va_loss: 0.1534 - val_expression_accuracy: 0.1250 - val_expression_loss: 106.6050 - val_loss: 107.3206 - val_va_loss: 0.7156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc13ac2",
   "metadata": {},
   "source": [
    "# Training Using EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f352d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = build_model(backbone=\"DenseNet121\", num_classes=df['expression'].nunique())\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"expression\": \"categorical_crossentropy\", \"va\": \"mse\"},\n",
    "    loss_weights={\"expression\": 1.0, \"va\": 1.0},\n",
    "    metrics={\"expression\": \"accuracy\"}\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.0' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cb984",
   "metadata": {},
   "source": [
    "# Evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, cohen_kappa_score, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facdefb6",
   "metadata": {},
   "source": [
    "# ---------------- Classification Metrics ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2cec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred, y_true_oh=None, y_pred_proba=None):\n",
    "    results = {}\n",
    "    results['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    results['F1'] = f1_score(y_true, y_pred, average='macro')\n",
    "    results['Kappa'] = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "    # ROC-AUC & PR-AUC need probabilities and one-hot labels\n",
    "    if y_true_oh is not None and y_pred_proba is not None:\n",
    "        try:\n",
    "            results['AUC'] = roc_auc_score(y_true_oh, y_pred_proba, average='macro', multi_class='ovr')\n",
    "        except:\n",
    "            results['AUC'] = None\n",
    "        try:\n",
    "            pr_auc_scores = []\n",
    "            for i in range(y_true_oh.shape[1]):\n",
    "                prec, rec, _ = precision_recall_curve(y_true_oh[:, i], y_pred_proba[:, i])\n",
    "                pr_auc_scores.append(auc(rec, prec))\n",
    "            results['AUC-PR'] = np.mean(pr_auc_scores)\n",
    "        except:\n",
    "            results['AUC-PR'] = None\n",
    "\n",
    "    # Krippendorff's Alpha (approximation via confusion matrix)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    n = np.sum(cm)\n",
    "    p = np.sum(cm, axis=1) / n\n",
    "    Do = 1 - np.trace(cm) / n\n",
    "    De = 1 - np.sum(p**2)\n",
    "    results['Alpha'] = 1 - Do / De if De != 0 else None\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77854a",
   "metadata": {},
   "source": [
    "# ---------------- Regression Metrics ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    results = {}\n",
    "    # RMSE\n",
    "    results['RMSE'] = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    # CORR\n",
    "    corr_v, _ = pearsonr(y_true[:,0], y_pred[:,0])\n",
    "    corr_a, _ = pearsonr(y_true[:,1], y_pred[:,1])\n",
    "    results['CORR'] = (corr_v, corr_a)\n",
    "    # SAGR\n",
    "    results['SAGR'] = np.mean(np.sign(y_true) == np.sign(y_pred), axis=0)\n",
    "    # CCC\n",
    "    def ccc(x,y):\n",
    "        x_mean, y_mean = np.mean(x), np.mean(y)\n",
    "        vx, vy = np.var(x), np.var(y)\n",
    "        cov = np.mean((x-x_mean)*(y-y_mean))\n",
    "        return (2*cov) / (vx+vy+(x_mean-y_mean)**2+1e-8)\n",
    "    results['CCC'] = (ccc(y_true[:,0], y_pred[:,0]), ccc(y_true[:,1], y_pred[:,1]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92a528",
   "metadata": {},
   "source": [
    "# Run model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls_proba, y_pred_reg = model.predict(X_val)\n",
    "y_true_cls_oh = y_val['expression']    \n",
    "y_true_reg    = y_val['va']            \n",
    "\n",
    "y_true_cls = np.argmax(y_true_cls_oh, axis=1)\n",
    "y_pred_cls = np.argmax(y_pred_cls_proba, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_results = classification_metrics(\n",
    "    y_true=y_true_cls,\n",
    "    y_pred=y_pred_cls,\n",
    "    y_true_oh=y_true_cls_oh,\n",
    "    y_pred_proba=y_pred_cls_proba\n",
    ")\n",
    "\n",
    "print(\"Classification metrics:\")\n",
    "for k, v in cls_results.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae77a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results = regression_metrics(\n",
    "    y_true=y_true_reg,\n",
    "    y_pred=y_pred_reg\n",
    ")\n",
    "print(\"Regression metrics:\")\n",
    "for k, v in reg_results.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad36d4c",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d2eaa",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df60723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true_cls, y_pred_cls)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44b8ab",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(y_true_cls_oh.shape[1]):\n",
    "    fpr, tpr, _ = roc_curve(y_true_cls_oh[:, i], y_pred_cls_proba[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f\"Class {i} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd6f76",
   "metadata": {},
   "source": [
    "# Regression of Scatter PLot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba9790",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_true_reg[:,0], y_pred_reg[:,0], alpha=0.5, label=\"Valence\")\n",
    "plt.scatter(y_true_reg[:,1], y_pred_reg[:,1], alpha=0.5, label=\"Arousal\")\n",
    "plt.plot([-1,1], [-1,1], 'r--')\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Valence/Arousal Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c7d925",
   "metadata": {},
   "source": [
    "# Error Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_true_reg - y_pred_reg\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(errors[:,0], bins=30, kde=True, color='blue', label='Valence Error')\n",
    "sns.histplot(errors[:,1], bins=30, kde=True, color='orange', label='Arousal Error')\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Error Distribution\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
